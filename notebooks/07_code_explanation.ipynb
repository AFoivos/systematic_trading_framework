{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# Systematic Trading Framework â€” Code Reference (Detailed)\n\nThis notebook is a **markdown-only reference** that documents what each module and every `def` function does, file by file, based on the current codebase.\n\n> Scope: `src/`, `config/`, and `tests/` modules that define functions/classes.\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## src/backtesting/engine.py\n\n### `BacktestResult`\n- Dataclass that packages backtest outputs: `equity_curve`, `returns`, `positions`, `turnover`, and `summary` metrics.\n\n### `_compute_summary(returns, periods_per_year=252)`\n- Cleans and computes key performance metrics from strategy returns:\n  - Cumulative return via cumulative product.\n  - Annualized return by scaling over `periods_per_year`.\n  - Annualized volatility from std * sqrt(periods_per_year).\n  - Sharpe ratio (`ann_ret / ann_vol`) with zero-handling.\n  - Max drawdown from equity curve.\n- Returns a dictionary of these metrics.\n\n### `run_backtest(df, signal_col, returns_col, cost_per_unit_turnover=0.0, slippage_per_unit_turnover=0.0, target_vol=None, vol_col=None, max_leverage=3.0, dd_guard=True, max_drawdown=0.2, cooloff_bars=20, periods_per_year=252)`\n- Vectorized backtest engine that:\n  - Validates the presence of `signal_col` and `returns_col`.\n  - Builds positions from the signal column (optionally vol-targeted via `vol_col`).\n  - Computes turnover and transaction costs (including slippage) as a function of turnover.\n  - Applies a drawdown guard that scales down exposure after drawdown breaches.\n  - Calculates and returns equity curve, returns, turnover, and summary stats.\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## src/backtesting/strategies.py\n\n### `buy_and_hold_signal(df, signal_name=\"signal_bh\")`\n- Produces a constant long-only signal (1.0) for all time steps.\n\n### `trend_state_long_only_signal(df, state_col, signal_name=\"signal_trend_state_long_only\")`\n- Converts a trend regime/state column into a long-only signal (1.0 when state > 0).\n\n### `trend_state_signal(df, state_col, signal_name=\"signal_trend_state\", mode=\"long_short_hold\")`\n- Wrapper around `compute_trend_state_signal` to generate regime-based signals in a specified mode.\n\n### `rsi_strategy(df, rsi_col, buy_level=30.0, sell_level=70.0, signal_name=\"signal_rsi\", mode=\"long_short_hold\")`\n- Wrapper around `compute_rsi_signal` to map RSI values into signals based on thresholds.\n\n### `momentum_strategy(df, momentum_col, long_threshold=0.0, short_threshold=None, signal_name=\"signal_momentum\", mode=\"long_short_hold\")`\n- Wrapper around `compute_momentum_signal`, with optional short threshold, to generate momentum-driven signals.\n\n### `stochastic_strategy(df, k_col, buy_level=20.0, sell_level=80.0, signal_name=\"signal_stochastic\", mode=\"long_short_hold\")`\n- Wrapper around `compute_stochastic_signal` for stochastic %K signals.\n\n### `volatility_regime_strategy(df, vol_col, quantile=0.5, signal_name=\"signal_volatility_regime\", mode=\"long_short_hold\")`\n- Wrapper around `compute_volatility_regime_signal` that goes long in low-vol regimes and short in high-vol regimes (mode permitting).\n\n### `probabilistic_signal(df, prob_col, signal_name=\"signal_prob\", upper=0.55, lower=0.45)`\n- Converts a probability forecast column into {-1, 0, 1} using upper/lower thresholds.\n\n### `conviction_sizing_signal(df, prob_col, signal_name=\"signal_prob_size\", clip=1.0)`\n- Maps probabilities into a continuous position size in [-clip, clip].\n\n### `regime_filtered_signal(df, base_signal_col, regime_col, signal_name=\"signal_regime_filtered\", active_value=1.0)`\n- Keeps a base signal only when a regime column equals a specific value, otherwise zeroes it out.\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## src/models/lightgbm_baseline.py\n\n### `default_feature_columns(df)`\n- Returns a default list of feature names (if present) expected to be created by the feature pipeline.\n\n### `LGBMBaselineConfig`\n- Dataclass holding default LightGBM hyperparameters for the baseline regressor.\n\n### `train_regressor(train_df, feature_cols, target_col, cfg=None)`\n- Fits an `LGBMRegressor` to the provided training data and returns the trained model.\n\n### `predict_returns(model, df, feature_cols, pred_col=\"pred_next_ret\")`\n- Uses a fitted model to generate return predictions and appends them as a new column.\n\n### `prediction_to_signal(df, pred_col=\"pred_next_ret\", signal_col=\"signal_lgb\", long_threshold=0.0, short_threshold=None)`\n- Maps predicted returns into discrete trade signals with thresholds.\n\n### `train_test_split_time(df, train_frac=0.7)`\n- Splits a DataFrame into time-ordered train/test sets without shuffling.\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## src/data/loaders.py\n\n### `load_ohlcv(symbol, start=None, end=None, interval=\"1d\", source=\"yahoo\", api_key=None)`\n- High-level loader that selects the proper provider (`YahooFinanceProvider` or `AlphaVantageFXProvider`) and returns OHLCV data in a standardized schema.\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## src/data/validation.py\n\n### `validate_ohlcv(df, required_columns=(\"open\", \"high\", \"low\", \"close\", \"volume\"), allow_missing_volume=True)`\n- Validates OHLCV data integrity:\n  - Required columns present.\n  - DatetimeIndex, monotonic ordering, and no duplicates.\n  - High/low/open/close consistency checks.\n  - Volume NaN handling depending on `allow_missing_volume`.\n- Raises `ValueError` with detailed errors if invalid.\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## src/data/providers/base.py\n\n### `MarketDataProvider.get_ohlcv(...)`\n- Abstract method that provider implementations must define to return OHLCV data.\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## src/data/providers/yahoo.py\n\n### `YahooFinanceProvider.get_ohlcv(symbol, start=None, end=None, interval=\"1d\")`\n- Uses `yfinance` to download OHLCV data, normalizes column names, validates expected fields, and cleans the index.\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## src/data/providers/alphavantage.py\n\n### `AlphaVantageFXProvider.get_ohlcv(symbol, start=None, end=None, interval=\"1d\")`\n- Calls the Alpha Vantage FX_DAILY API and converts JSON to OHLCV DataFrame.\n- Validates API key and symbol format (e.g., `EURUSD`).\n- Adds a `volume` column (0.0) since FX data does not provide volume.\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## src/utils/config.py\n\n### `ConfigError`\n- Custom exception raised for invalid or inconsistent experiment configs.\n\n### `_resolve_config_path(config_path)`\n- Resolves a config path relative to `config/` or project root and ensures it exists.\n\n### `_load_yaml(path)`\n- Loads YAML and ensures the top-level is a dictionary.\n\n### `_deep_update(base, updates)`\n- Recursive merge of nested dicts; scalars and lists are overwritten.\n\n### `_load_with_extends(path, seen=None)`\n- Loads a config file and resolves inheritance via `extends` while preventing cycles.\n\n### `_default_risk_block(risk)`\n- Applies defaults for cost, slippage, target volatility, leverage, and drawdown guard settings.\n\n### `_default_backtest_block(backtest)`\n- Applies defaults for backtest settings (e.g., `periods_per_year`, `returns_type`).\n\n### `_resolve_logging_block(logging_cfg, config_path)`\n- Resolves logging output directory and default run name.\n\n### `_validate_data_block(data)`\n- Ensures required data settings (symbol, source, interval) are valid.\n\n### `_inject_api_key_from_env(data)`\n- Pulls API keys from environment into the config when requested.\n\n### `_validate_features_block(features)`\n- Ensures features are a list of `step` dictionaries.\n\n### `_validate_model_block(model)`\n- Ensures a model `kind` string is defined.\n\n### `_validate_signals_block(signals)`\n- Ensures signals `kind` string is defined.\n\n### `_validate_risk_block(risk)`\n- Validates numeric bounds for costs, vol targeting, leverage, and drawdown guard values.\n\n### `_validate_backtest_block(backtest)`\n- Ensures `returns_col` and `signal_col` are defined, and validates `returns_type`.\n\n### `load_experiment_config(config_path)`\n- Full config loader that applies inheritance, defaults, validation, and logging resolution.\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## src/utils/paths.py\n\n### `in_project(*parts)`\n- Joins a path relative to the project root.\n\n### `ensure_directories_exist()`\n- Creates expected project directories (config, data, logs, etc.).\n\n### `describe_paths()`\n- Prints core project paths for debugging.\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## src/experiments/registry.py\n\n### Registries (`FEATURE_REGISTRY`, `SIGNAL_REGISTRY`, `MODEL_REGISTRY`)\n- Mapping tables linking string names (in YAML config) to python functions.\n\n### `get_feature_fn(name)`\n- Returns the feature function for a named step, or raises if unknown.\n\n### `get_signal_fn(name)`\n- Returns the signal function for a named step, or raises if unknown.\n\n### `get_model_fn(name)`\n- Returns the model function for a named step, or raises if unknown.\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## src/experiments/models.py\n\n### `infer_feature_columns(df, explicit_cols=None, exclude=None)`\n- Determines feature columns for model training, using explicit list, defaults, or heuristics over numeric columns.\n\n### `_build_forward_return_target(df, target_cfg=None)`\n- Builds a forward return target column and a binary label column based on threshold/quantiles.\n\n### `train_lightgbm_classifier(df, model_cfg, returns_col=None)`\n- Trains a LightGBM classifier using time-based split and writes prediction probabilities to the dataset.\n- Returns the updated DataFrame, trained model, and metadata including split info and target details.\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## src/experiments/runner.py\n\n### `ExperimentResult`\n- Dataclass storing the resolved config, data, backtest result, model, model metadata, and artifact paths.\n\n### `_apply_feature_steps(df, steps)`\n- Applies each feature step in config order via the registry.\n\n### `_apply_model_step(df, model_cfg, returns_col)`\n- Trains model if `kind != \"none\"`, otherwise returns data unchanged.\n\n### `_apply_signal_step(df, signals_cfg)`\n- Generates signal columns via registry; supports DataFrame or Series outputs.\n\n### `_resolve_vol_col(df, backtest_cfg, risk_cfg)`\n- Finds which volatility column to use for targeting (config or heuristics).\n\n### `_validate_returns_series(returns, returns_type)`\n- Performs validation on return series; currently checks simple returns for values < -1.\n\n### `_save_artifacts(run_dir, cfg, data, bt, model_meta)`\n- Writes config and backtest artifacts (summary, equity, returns, positions, turnover) to disk.\n\n### `run_experiment(config_path)`\n- End-to-end pipeline: load config, load data, apply features, train model, generate signals, run backtest, and optionally log artifacts.\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## src/features/returns.py\n\n### `compute_returns(prices, log=False, dropna=True)`\n- Computes simple returns (P_t / P_{t-1} - 1) or log returns (log(P_t / P_{t-1})).\n\n### `add_close_returns(df, log=False, col_name=None)`\n- Adds a close returns column to the DataFrame using `compute_returns`.\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## src/features/lags.py\n\n### `add_lagged_features(df, cols, lags=(1,2,5), prefix=\"lag\")`\n- Adds lagged versions of the specified columns using the given lags.\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## src/features/volatility.py\n\n### `compute_rolling_vol(returns, window, ddof=1, annualization_factor=None)`\n- Computes rolling volatility from returns, optionally annualized.\n\n### `compute_ewma_vol(returns, span, annualization_factor=None)`\n- Computes EWMA volatility from returns, optionally annualized.\n\n### `add_volatility_features(df, returns_col=\"close_logret\", rolling_windows=(10,20,60), ewma_spans=(10,20), annualization_factor=252.0, inplace=False)`\n- Adds rolling and EWMA volatility features to the DataFrame.\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## src/features/technical/indicators.py\n\n### `compute_true_range(high, low, close)`\n- Computes true range as max of (high-low, |high-prev_close|, |low-prev_close|).\n\n### `compute_atr(high, low, close, window=14, method=\"wilder\")`\n- Computes Average True Range (ATR) using Wilder smoothing or SMA.\n\n### `add_bollinger_bands(close, window=20, n_std=2.0)`\n- Builds Bollinger band features including band width and %B.\n\n### `compute_macd(close, fast=12, slow=26, signal=9)`\n- Computes MACD line, signal line, and histogram.\n\n### `compute_ppo(close, fast=12, slow=26, signal=9)`\n- Computes Percentage Price Oscillator (PPO) and related features.\n\n### `compute_roc(close, window=10)`\n- Computes Rate of Change (ROC) indicator.\n\n### `compute_volume_zscore(volume, window=20)`\n- Computes rolling z-score of volume.\n\n### `compute_adx(high, low, close, window=14)`\n- Computes ADX along with DI+ and DI-.\n\n### `compute_mfi(high, low, close, volume, window=14)`\n- Computes Money Flow Index (MFI).\n\n### `add_indicator_features(df, price_col=\"close\", high_col=\"high\", low_col=\"low\", volume_col=\"volume\", ...)`\n- Adds a large bundle of indicator features (Bollinger, MACD, PPO, ROC, ATR, volume z-score, ADX, MFI) to the DataFrame.\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## src/features/technical/trend.py\n\n### `compute_sma(prices, window, min_periods=None)`\n- Computes Simple Moving Average and names it based on input series.\n\n### `compute_ema(prices, span, adjust=False)`\n- Computes Exponential Moving Average and names it based on input series.\n\n### `add_trend_features(df, price_col=\"close\", sma_windows=(20,50,200), ema_spans=(20,50), inplace=False)`\n- Adds SMA/EMA and relative price vs MA features.\n\n### `add_trend_regime_features(df, price_col=\"close\", base_sma_for_sign=50, short_sma=20, long_sma=50, inplace=False)`\n- Adds trend regime/state features using SMA cross and sign of `price_over_sma`.\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## src/features/technical/momentum.py\n\n### `compute_price_momentum(prices, window)`\n- Computes price momentum as P_t / P_{t-window} - 1.\n\n### `compute_return_momentum(returns, window)`\n- Computes cumulative return momentum over a window.\n\n### `compute_vol_normalized_momentum(returns, volatility, window, eps=1e-8)`\n- Computes momentum normalized by volatility.\n\n### `add_momentum_features(df, price_col=\"close\", returns_col=\"close_logret\", vol_col=\"vol_rolling_20\", windows=(5,20,60), inplace=False)`\n- Adds price momentum, return momentum, and vol-normalized momentum features.\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## src/features/technical/oscillators.py\n\n### `compute_rsi(prices, window=14, method=\"wilder\")`\n- Computes RSI using Wilder (EWMA) or simple average method.\n\n### `compute_stoch_k(close, high, low, window=14)`\n- Computes stochastic %K.\n\n### `compute_stoch_d(k, smooth=3)`\n- Computes stochastic %D (moving average of %K).\n\n### `add_oscillator_features(df, price_col=\"close\", high_col=\"high\", low_col=\"low\", rsi_windows=(14,), stoch_windows=(14,), stoch_smooth=3, inplace=False)`\n- Adds RSI and stochastic oscillator features to the DataFrame.\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## src/features/technical/__init__.py & src/features/__init__.py\n\n- Expose feature functions at package level for easier imports and registry usage.\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## src/signals/trend_signal.py\n\n### `compute_trend_state_signal(df, state_col, signal_col=\"trend_state_signal\", long_value=1.0, flat_value=0.0, short_value=-1.0, mode=\"long_short_hold\")`\n- Converts a trend state column into a trading signal based on `mode`.\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## src/signals/momentum_signal.py\n\n### `compute_momentum_signal(df, momentum_col, long_threshold=0.0, short_threshold=None, signal_col=\"momentum_signal\", mode=\"long_short_hold\")`\n- Converts a momentum feature into discrete trade signals.\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## src/signals/rsi_signal.py\n\n### `compute_rsi_signal(df, rsi_col, buy_level, sell_level, signal_col=\"rsi_signal\", mode=\"long_short_hold\")`\n- Generates signals based on RSI thresholds for buy/sell levels.\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## src/signals/volatility_signal.py\n\n### `compute_volatility_regime_signal(df, vol_col, quantile=0.5, signal_col=\"volatility_regime_signal\", mode=\"long_short_hold\")`\n- Generates regime signals: long when vol <= quantile, short when vol > quantile.\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## src/signals/stochastic_signal.py\n\n### `compute_stochastic_signal(df, k_col, buy_level=20.0, sell_level=80.0, signal_col=\"stochastic_signal\", mode=\"long_short_hold\")`\n- Generates signals based on stochastic %K thresholds.\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## src/risk/position_sizing.py\n\n### `compute_vol_target_leverage(vol, target_vol, max_leverage=3.0, min_leverage=0.0, eps=1e-8)`\n- Computes target leverage as `target_vol / vol`, clipped to allowed bounds.\n\n### `scale_signal_by_vol(signal, vol, target_vol, max_leverage=3.0, min_leverage=0.0, eps=1e-8)`\n- Scales a trading signal by volatility-target leverage.\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## src/risk/controls.py\n\n### `compute_drawdown(equity)`\n- Computes drawdown series from equity curve.\n\n### `drawdown_cooloff_multiplier(equity, max_drawdown=0.2, cooloff_bars=20, min_exposure=0.0)`\n- When drawdown breaches threshold, reduces exposure for a cooling-off period.\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## src/data/__init__.py, src/models/__init__.py, src/signals/__init__.py, src/risk/__init__.py, src/evaluation/__init__.py\n\n- Package initializers that expose submodules or mark packages for import; no functions defined.\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## tests/conftest.py\n\n### Path setup\n- Ensures the project root is on `sys.path` so tests can import `src.*` modules.\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## tests/test_core.py\n\n### `test_compute_returns_simple_and_log()`\n- Validates numeric correctness of simple and log return computations.\n\n### `test_add_trend_features_columns()`\n- Ensures trend features create expected columns.\n\n### `test_validate_ohlcv_flags_invalid_high_low()`\n- Ensures invalid OHLCV inputs are rejected.\n\n### `test_run_backtest_costs_and_slippage_reduce_returns()`\n- Ensures applying costs+slippage reduces overall strategy returns.\n"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}

